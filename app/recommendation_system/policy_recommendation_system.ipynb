{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9753b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGINGFACE_API_KEY=\"\"\n",
    "GROQ_API_KEY=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47b952a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import getpass \n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17e92ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HUGGINGFACE_API_TOKEN']=HUGGINGFACE_API_KEY\n",
    "os.environ['GROQ_API_KEY']=GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce90fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65a513f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8dbfa2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "import faiss \n",
    "import pandas as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "653fc944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aarav Sharma\\AppData\\Local\\Temp\\ipykernel_6080\\1837158031.py:1: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings=HuggingFaceEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "embeddings=HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a7bd1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_vectorstore=FAISS.load_local(\"policy_faiss_index\",embeddings,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc00d18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_vectorstore=FAISS.load_local(\"profile_faiss_index\",embeddings,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fe8349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA,LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9daf8227",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_template=\"\"\"\n",
    "Suggest similar SBI Life policies on the basis of the input taken from the user and the profiles having similar background as the user.\n",
    "The user data is also provided below:\n",
    "Name:{name},\n",
    "Age:{age},\n",
    "Occupaion:{occupation},\n",
    "Education:{education},\n",
    "Annual Income:{income}\n",
    "Provide complete answers with the name of the policies being suggested, their key benefits, the type of policy, the url, anuual premium range and entry age. Suggest only the relavant policies.\n",
    "\"\"\"\n",
    "prompt_manual = PromptTemplate(\n",
    "    input_variables=[\"name\",\"age\",\"occupation\",\"education\",\"income\"],\n",
    "    template=manual_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a62727b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.base import VectorStoreRetriever\n",
    "class AsyncMultiVectorRetriever():\n",
    "    def __init__(self, retrievers):\n",
    "        \"\"\"Initialize with multiple retrievers (vector stores).\"\"\"\n",
    "        self.retrievers = retrievers\n",
    "\n",
    "    async def get_relevant_documents(self, query):\n",
    "        \"\"\"Fetch relevant documents from all vector stores.\"\"\"\n",
    "        docs = []\n",
    "        tasks = [asyncio.to_thread(retriever.get_relevant_documents, query) for retriever in self.retrievers]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        return [doc for docs in results for doc in docs]\n",
    "multi_retriever = AsyncMultiVectorRetriever(retrievers=[profile_vectorstore, policy_vectorstore])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a33adf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_template=\"\"\"\n",
    "You are a friendly, conversational SBI Life policy recommendation assistant that helps customers find SBI Life policies that match their profile and background information.\n",
    "This includes their occupation, education, annual income, their existing policies and most important of all for what purpose they need a policy. \n",
    "From the following context and chat history, assist customers in finding what they are looking for based on their input. \n",
    "For each question, suggest three policies, including their name, type, key benefits, annual premium range, entry age and url.\n",
    "Similar orthe same profile as the user will also be retrieved. Using these profiles make your suggestions as well. \n",
    "If you don't have any policy to suggest, then just say you don't have any policy to suggest as per the requirements, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "chat history:{history}\n",
    "\n",
    "input:{question}\n",
    "\n",
    "Your response:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "912751bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_prompt=PromptTemplate(input_variables=[\"context\",\"history\",\"question\"],template=chatbot_template)\n",
    "memory = ConversationBufferMemory(memory_key=\"history\", input_key=\"question\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6462f598",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "qa_chain = LLMChain(llm=llm, prompt=chatbot_prompt, verbose=True)\n",
    "#while True:\n",
    "    #query = input(\"\\nUser: \")  \n",
    "    #if query.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "        #print(\"\\nChatbot: Goodbye!\")\n",
    "        #break  \n",
    "    #retrieved_docs = retrieve_documents(query)\n",
    "    #retrieved_text = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    #response = qa.run(context=retrieved_text)  \n",
    "    #response = qa_chain.run(context=multi_retriever, history=memory.load_memory_variables({})[\"history\"], question=query)\n",
    "    #memory.save_context({\"question\": query}, {\"response\": response})\n",
    "    #print(\"\\nChatbot:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23b8a722",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_chat_loop():\n",
    "    while True:\n",
    "        query = input(\"\\nUser: \")\n",
    "        if query.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"\\nChatbot: Goodbye!\")\n",
    "            break\n",
    "        chat_history = await asyncio.to_thread(memory.load_memory_variables, {})  \n",
    "        response = await asyncio.to_thread(\n",
    "            qa_chain.run,\n",
    "            context=multi_retriever, \n",
    "            history=chat_history[\"history\"],\n",
    "            question=query\n",
    "        )\n",
    "        await asyncio.to_thread(memory.save_context, {\"question\": query}, {\"response\": response})\n",
    "\n",
    "        print(\"\\nChatbot:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97ffa43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    print(\"Welcome to SBI Life Policy Assistant! Type 'exit' to quit.\\n\")\n",
    "    await async_chat_loop()  # Run chatbot asynchronously\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b0a5e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to SBI Life Policy Assistant! Type 'exit' to quit.\n",
      "\n",
      "\n",
      "User: exit\n",
      "\n",
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()  # Allow nested event loops\n",
    "    await main()  # Directly await the main function\n",
    "except RuntimeError:\n",
    "    # If no event loop is running, use asyncio.run()\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896d0a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
